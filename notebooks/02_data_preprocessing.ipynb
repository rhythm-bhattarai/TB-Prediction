{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c8292bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIAL DATA INSPECTION\n",
      "============================================================\n",
      "Shape: (112497, 20)\n",
      "\n",
      "Column names (RAW):\n",
      "0: 'District'\n",
      "1: 'Date'\n",
      "2: 'AQI'\n",
      "3: 'CO '\n",
      "4: 'Humidity'\n",
      "5: 'NH3'\n",
      "6: 'NO2 '\n",
      "7: 'O3 '\n",
      "8: 'PM10 '\n",
      "9: 'PM2.5'\n",
      "10: 'Precipitation '\n",
      "11: 'Air Pressure'\n",
      "12: 'SO2'\n",
      "13: 'Solar Radiation'\n",
      "14: 'TB Case'\n",
      "15: 'Avg Temp'\n",
      "16: 'Temp Max '\n",
      "17: 'Temp Min '\n",
      "18: 'Wind Pressure'\n",
      "19: 'Wind Speed'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/raw/tb_climate_data.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATA INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names (RAW):\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i}: '{col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f7fae1f-bf17-4cac-ad30-292625e57c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING COLUMN NAMES\n",
      "============================================================\n",
      "BEFORE cleaning:\n",
      "['District', 'Date', 'AQI', 'CO ', 'Humidity', 'NH3', 'NO2 ', 'O3 ', 'PM10 ', 'PM2.5', 'Precipitation ', 'Air Pressure', 'SO2', 'Solar Radiation', 'TB Case', 'Avg Temp', 'Temp Max ', 'Temp Min ', 'Wind Pressure', 'Wind Speed']\n",
      "\n",
      "AFTER cleaning:\n",
      "['District', 'Date', 'AQI', 'CO', 'Humidity', 'NH3', 'NO2', 'O3', 'PM10', 'PM2.5', 'Precipitation', 'Air Pressure', 'SO2', 'Solar Radiation', 'TB Case', 'Avg Temp', 'Temp Max', 'Temp Min', 'Wind Pressure', 'Wind Speed']\n",
      "\n",
      "Checking specific columns:\n",
      "-> 'Temp Max' found\n",
      "-> 'Temp Min' found\n",
      "-> 'TB Case' found\n",
      "-> 'Avg Temp' found\n"
     ]
    }
   ],
   "source": [
    "# clean column names\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLEANING COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show before\n",
    "print(\"BEFORE cleaning:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Strip whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Show after\n",
    "print(\"\\nAFTER cleaning:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Verify specific columns\n",
    "test_cols = ['Temp Max', 'Temp Min', 'TB Case', 'Avg Temp']\n",
    "print(f\"\\nChecking specific columns:\")\n",
    "for col in test_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"-> '{col}' found\")\n",
    "    else:\n",
    "        print(f\"* '{col}' NOT found\")\n",
    "        # Find similar names\n",
    "        similar = [c for c in df.columns if col.lower() in c.lower()]\n",
    "        if similar:\n",
    "            print(f\"   Similar names found: {similar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdf1b9cc-5f9d-4354-b31b-19a21ee39f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA TYPES INSPECTION\n",
      "============================================================\n",
      "District            object\n",
      "Date                object\n",
      "AQI                float64\n",
      "CO                 float64\n",
      "Humidity           float64\n",
      "NH3                float64\n",
      "NO2                float64\n",
      "O3                 float64\n",
      "PM10               float64\n",
      "PM2.5              float64\n",
      "Precipitation      float64\n",
      "Air Pressure       float64\n",
      "SO2                float64\n",
      "Solar Radiation    float64\n",
      "TB Case            float64\n",
      "Avg Temp           float64\n",
      "Temp Max           float64\n",
      "Temp Min           float64\n",
      "Wind Pressure      float64\n",
      "Wind Speed         float64\n",
      "dtype: object\n",
      "\n",
      "Checking for non-numeric values in numeric columns:\n",
      "\n",
      "District:\n",
      "  Sample values: ['Achham', 'Achham', 'Achham', 'Achham', 'Achham']\n",
      "  * Contains non-numeric values: ['Achham' 'Arghakhanchi' 'Baglung' 'Baitadi' 'Bajhang']\n",
      "\n",
      "Date:\n",
      "  Sample values: ['1/1/2021', '2/1/2021', '3/1/2021', '4/1/2021', '5/1/2021']\n",
      "  * Contains non-numeric values: ['1/1/2021' '2/1/2021' '3/1/2021' '4/1/2021' '5/1/2021']\n"
     ]
    }
   ],
   "source": [
    "# check and fix data types\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA TYPES INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any columns that should be numeric but aren't\n",
    "print(\"\\nChecking for non-numeric values in numeric columns:\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['district', 'date']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Sample values: {df[col].head().tolist()}\")\n",
    "    \n",
    "    # Try to find non-numeric values\n",
    "    try:\n",
    "        pd.to_numeric(df[col])\n",
    "        print(f\"  -> Can be converted to numeric\")\n",
    "    except:\n",
    "        non_numeric = df[~df[col].apply(lambda x: str(x).replace('.','').replace('-','').isdigit())]\n",
    "        print(f\"  * Contains non-numeric values: {non_numeric[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "292acab0-8e5a-45b0-b1e8-40cc593286fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STANDARDIZING COLUMN NAMES\n",
      "============================================================\n",
      "Column names standardized:\n",
      "['district', 'date', 'aqi', 'co', 'humidity', 'nh3', 'no2', 'o3', 'pm10', 'pm25', 'precipitation', 'air_pressure', 'so2', 'solar_radiation', 'tb_case', 'avg_temp', 'temp_max', 'temp_min', 'wind_pressure', 'wind_speed']\n"
     ]
    }
   ],
   "source": [
    "# standardize column names\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STANDARDIZING COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a mapping dictionary for cleaner, consistent names\n",
    "column_mapping = {\n",
    "    'District': 'district',\n",
    "    'Date': 'date',\n",
    "    'AQI': 'aqi',\n",
    "    'CO': 'co',\n",
    "    'Humidity': 'humidity',\n",
    "    'NH3': 'nh3',\n",
    "    'NO2': 'no2',\n",
    "    'O3': 'o3',\n",
    "    'PM10': 'pm10',\n",
    "    'PM2.5': 'pm25',\n",
    "    'Precipitation': 'precipitation',\n",
    "    'Air Pressure': 'air_pressure',\n",
    "    'SO2': 'so2',\n",
    "    'Solar Radiation': 'solar_radiation',\n",
    "    'TB Case': 'tb_case',\n",
    "    'Avg Temp': 'avg_temp',\n",
    "    'Temp Max': 'temp_max',\n",
    "    'Temp Min': 'temp_min',\n",
    "    'Wind Pressure': 'wind_pressure',\n",
    "    'Wind Speed': 'wind_speed'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "print(\"Column names standardized:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71dae90a-739f-4d3e-bb69-fc481b87b92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA TYPES INSPECTION\n",
      "============================================================\n",
      "district            object\n",
      "date                object\n",
      "aqi                float64\n",
      "co                 float64\n",
      "humidity           float64\n",
      "nh3                float64\n",
      "no2                float64\n",
      "o3                 float64\n",
      "pm10               float64\n",
      "pm25               float64\n",
      "precipitation      float64\n",
      "air_pressure       float64\n",
      "so2                float64\n",
      "solar_radiation    float64\n",
      "tb_case            float64\n",
      "avg_temp           float64\n",
      "temp_max           float64\n",
      "temp_min           float64\n",
      "wind_pressure      float64\n",
      "wind_speed         float64\n",
      "dtype: object\n",
      "\n",
      "Checking for non-numeric values in numeric columns:\n"
     ]
    }
   ],
   "source": [
    "# check and fix data types\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA TYPES INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any columns that should be numeric but aren't\n",
    "print(\"\\nChecking for non-numeric values in numeric columns:\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['district', 'date']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Sample values: {df[col].head().tolist()}\")\n",
    "    \n",
    "    # Try to find non-numeric values\n",
    "    try:\n",
    "        pd.to_numeric(df[col])\n",
    "        print(f\"  -> Can be converted to numeric\")\n",
    "    except:\n",
    "        non_numeric = df[~df[col].apply(lambda x: str(x).replace('.','').replace('-','').isdigit())]\n",
    "        print(f\"  * Contains non-numeric values: {non_numeric[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd65f179-b01d-4524-841a-eb92736a521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKING FOR DUPLICATES\n",
      "============================================================\n",
      "Complete duplicate rows: 0\n",
      "\n",
      "Duplicate (district, date) combinations: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING FOR DUPLICATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for complete duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Complete duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Removing duplicates...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"-> {duplicates} duplicate rows removed\")\n",
    "\n",
    "# Check for duplicates based on district and date\n",
    "duplicate_keys = df.duplicated(subset=['district', 'date']).sum()\n",
    "print(f\"\\nDuplicate (district, date) combinations: {duplicate_keys}\")\n",
    "\n",
    "if duplicate_keys > 0:\n",
    "    print(\"# Warning: Multiple entries for same district and date\")\n",
    "    print(\"Sample duplicates:\")\n",
    "    print(df[df.duplicated(subset=['district', 'date'], keep=False)].head(10))\n",
    "    \n",
    "    # Option 1: Keep first occurrence\n",
    "    # df = df.drop_duplicates(subset=['district', 'date'], keep='first')\n",
    "    \n",
    "    # Option 2: Average the values (better for numeric data)\n",
    "    print(\"\\nAveraging duplicate entries...\")\n",
    "    df = df.groupby(['district', 'date'], as_index=False).mean()\n",
    "    print(f\"-> Duplicates averaged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b993419-71fd-41b8-a919-4907a0d2481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKING FOR INVALID VALUES\n",
      "============================================================\n",
      "# pm10: 77 negative values found\n",
      "   Min value: -415.31\n",
      "   -> Negative values replaced with NaN\n",
      "\n",
      "Checking for extreme outliers:\n"
     ]
    }
   ],
   "source": [
    "# check for invalid values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING FOR INVALID VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for negative values where they shouldn't exist\n",
    "check_positive = ['tb_case', 'pm25', 'pm10', 'aqi', 'humidity', 'precipitation']\n",
    "\n",
    "for col in check_positive:\n",
    "    if col in df.columns:\n",
    "        negative_count = (df[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"# {col}: {negative_count} negative values found\")\n",
    "            print(f\"   Min value: {df[col].min()}\")\n",
    "            # Replace negative with NaN (will be imputed later)\n",
    "            df.loc[df[col] < 0, col] = np.nan\n",
    "            print(f\"   -> Negative values replaced with NaN\")\n",
    "\n",
    "# Check for unrealistic values (outliers)\n",
    "print(\"\\nChecking for extreme outliers:\")\n",
    "\n",
    "# Example: Temperature should be reasonable (-50 to 50°C)\n",
    "if 'avg_temp' in df.columns:\n",
    "    extreme_temp = ((df['avg_temp'] < -50) | (df['avg_temp'] > 50)).sum()\n",
    "    if extreme_temp > 0:\n",
    "        print(f\"# avg_temp: {extreme_temp} extreme values found\")\n",
    "\n",
    "# Humidity should be 0-100%\n",
    "if 'humidity' in df.columns:\n",
    "    extreme_humidity = ((df['humidity'] < 0) | (df['humidity'] > 100)).sum()\n",
    "    if extreme_humidity > 0:\n",
    "        print(f\"# humidity: {extreme_humidity} values outside 0-100% range\")\n",
    "        df.loc[(df['humidity'] < 0) | (df['humidity'] > 100), 'humidity'] = np.nan\n",
    "        print(f\"   -> Invalid values replaced with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "271ee068-419f-4545-bbb9-4d3a07c04460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SORTING DATA\n",
      "============================================================\n",
      "✅ Data sorted by district and date\n",
      "\n",
      "Date range: 1/1/2021 to 9/9/2024\n",
      "Number of districts: 77\n"
     ]
    }
   ],
   "source": [
    "# sorting data properly\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SORTING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by district and date\n",
    "df = df.sort_values(['district', 'date'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Data sorted by district and date\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c183f69a-e44a-4a00-81ac-d38441014c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA CLEANING SUMMARY\n",
      "======================================================================\n",
      "Final shape: (112497, 20)\n",
      "\n",
      "Column names (cleaned):\n",
      "   0. district\n",
      "   1. date\n",
      "   2. aqi\n",
      "   3. co\n",
      "   4. humidity\n",
      "   5. nh3\n",
      "   6. no2\n",
      "   7. o3\n",
      "   8. pm10\n",
      "   9. pm25\n",
      "  10. precipitation\n",
      "  11. air_pressure\n",
      "  12. so2\n",
      "  13. solar_radiation\n",
      "  14. tb_case\n",
      "  15. avg_temp\n",
      "  16. temp_max\n",
      "  17. temp_min\n",
      "  18. wind_pressure\n",
      "  19. wind_speed\n",
      "\n",
      "Data types:\n",
      "district            object\n",
      "date                object\n",
      "aqi                float64\n",
      "co                 float64\n",
      "humidity           float64\n",
      "nh3                float64\n",
      "no2                float64\n",
      "o3                 float64\n",
      "pm10               float64\n",
      "pm25               float64\n",
      "precipitation      float64\n",
      "air_pressure       float64\n",
      "so2                float64\n",
      "solar_radiation    float64\n",
      "tb_case            float64\n",
      "avg_temp           float64\n",
      "temp_max           float64\n",
      "temp_min           float64\n",
      "wind_pressure      float64\n",
      "wind_speed         float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "aqi          308\n",
      "co           308\n",
      "nh3          308\n",
      "no2          308\n",
      "o3           308\n",
      "pm10         385\n",
      "pm25         308\n",
      "so2          308\n",
      "tb_case    61964\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "                 aqi             co       humidity            nh3  \\\n",
      "count  112189.000000  112189.000000  112497.000000  112189.000000   \n",
      "mean        3.059435     648.879823      67.166971       7.345359   \n",
      "std         1.459724     549.318139      20.639562       9.993657   \n",
      "min         1.000000      96.940000       6.530000       0.020000   \n",
      "25%         2.000000     356.730000      51.030000       1.660000   \n",
      "50%         3.000000     501.790000      71.600000       4.360000   \n",
      "75%         5.000000     737.110000      85.550000       9.150000   \n",
      "max         5.000000    8117.680000      99.760000     164.150000   \n",
      "\n",
      "                 no2             o3           pm10          pm25  \\\n",
      "count  112189.000000  112189.000000  112112.000000  112189.00000   \n",
      "mean        5.015127      56.181157      65.109189      51.50960   \n",
      "std        17.639582      25.756311      78.807305      65.67648   \n",
      "min      -416.580000    -403.940000       0.550000       0.50000   \n",
      "25%         1.330000      39.260000      14.140000      10.82000   \n",
      "50%         2.950000      56.470000      37.530000      28.05000   \n",
      "75%         6.500000      71.600000      84.130000      64.90000   \n",
      "max       131.240000     203.830000    1009.750000     876.17000   \n",
      "\n",
      "       precipitation   air_pressure            so2  solar_radiation  \\\n",
      "count  112497.000000  112497.000000  112189.000000    112497.000000   \n",
      "mean        4.302973      84.888671       2.373668         4.515886   \n",
      "std         9.878226      11.441841       4.144131         1.361215   \n",
      "min         0.000000      54.220000       0.000000         0.390000   \n",
      "25%         0.000000      78.930000       0.460000         3.640000   \n",
      "50%         0.210000      87.530000       1.210000         4.420000   \n",
      "75%         4.270000      96.020000       2.630000         5.410000   \n",
      "max       165.520000     101.260000      82.020000         9.430000   \n",
      "\n",
      "            tb_case       avg_temp       temp_max       temp_min  \\\n",
      "count  50533.000000  112497.000000  112497.000000  112497.000000   \n",
      "mean       2.720579      17.076049      22.369275      12.874796   \n",
      "std        2.479356       9.173739       8.882772       9.452564   \n",
      "min        1.000000     -24.230000     -14.200000     -34.500000   \n",
      "25%        1.000000      11.960000      17.350000       7.710000   \n",
      "50%        2.000000      18.130000      23.180000      14.000000   \n",
      "75%        4.000000      23.570000      28.240000      20.080000   \n",
      "max       66.000000      40.780000      48.270000      33.980000   \n",
      "\n",
      "       wind_pressure     wind_speed  \n",
      "count  112497.000000  112497.000000  \n",
      "mean        1.768945       1.612539  \n",
      "std         1.419338       0.536169  \n",
      "min         0.080000       0.370000  \n",
      "25%         0.940000       1.240000  \n",
      "50%         1.430000       1.530000  \n",
      "75%         2.120000       1.860000  \n",
      "max        32.730000       7.310000  \n",
      "\n",
      "✅ Cleaned data saved to 'data/processed/tb_data_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"\\nColumn names (cleaned):\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No missing values\")\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# save cleaned data\n",
    "df.to_csv('data/processed/tb_data_cleaned.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved to 'data/processed/tb_data_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f783f981-d0b5-4bc6-9142-0d80d1f35433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# clean data import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"-> Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00bbc3cc-76d1-4629-b516-7f9ab1143484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANED DATA LOADED\n",
      "============================================================\n",
      "Shape: (112497, 20)\n",
      "\n",
      "Date range: 2021-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Number of districts: 77\n",
      "\n",
      "Columns (20):\n",
      "['district', 'date', 'aqi', 'co', 'humidity', 'nh3', 'no2', 'o3', 'pm10', 'pm25', 'precipitation', 'air_pressure', 'so2', 'solar_radiation', 'tb_case', 'avg_temp', 'temp_max', 'temp_min', 'wind_pressure', 'wind_speed']\n",
      "\n",
      "-> Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load CLEANED data\n",
    "df = pd.read_csv('data/processed/tb_data_cleaned.csv')\n",
    "\n",
    "# Convert date to datetime (just in case)\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst = True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLEANED DATA LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")\n",
    "print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n-> Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "558c6619-876e-4258-a77d-ba5a7f3104ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: REMOVING REDUNDANT FEATURES\n",
      "============================================================\n",
      "-> Removing 7 features:\n",
      "   1. temp_max\n",
      "   2. temp_min\n",
      "   3. aqi\n",
      "   4. wind_pressure\n",
      "   5. air_pressure\n",
      "   6. wind_speed\n",
      "   7. pm25\n",
      "\n",
      "-> Features removed successfully!\n",
      "\n",
      "Before: 13 columns\n",
      "After:  71 columns\n",
      "Removed: 7 columns\n",
      "\n",
      "Remaining features (71):\n",
      "   1. district\n",
      "   2. date\n",
      "   3. co\n",
      "   4. humidity\n",
      "   5. nh3\n",
      "   6. no2\n",
      "   7. o3\n",
      "   8. pm10\n",
      "   9. precipitation\n",
      "  10. so2\n",
      "  11. solar_radiation\n",
      "  12. tb_case\n",
      "  13. avg_temp\n",
      "  14. tb_case_lag_7\n",
      "  15. tb_case_lag_14\n",
      "  16. tb_case_lag_30\n",
      "  17. avg_temp_lag_7\n",
      "  18. avg_temp_lag_14\n",
      "  19. avg_temp_lag_30\n",
      "  20. humidity_lag_7\n",
      "  21. humidity_lag_14\n",
      "  22. humidity_lag_30\n",
      "  23. precipitation_lag_7\n",
      "  24. precipitation_lag_14\n",
      "  25. precipitation_lag_30\n",
      "  26. pm10_lag_7\n",
      "  27. pm10_lag_14\n",
      "  28. pm10_lag_30\n",
      "  29. so2_lag_7\n",
      "  30. so2_lag_14\n",
      "  31. so2_lag_30\n",
      "  32. no2_lag_7\n",
      "  33. no2_lag_14\n",
      "  34. no2_lag_30\n",
      "  35. co_lag_7\n",
      "  36. co_lag_14\n",
      "  37. co_lag_30\n",
      "  38. o3_lag_7\n",
      "  39. o3_lag_14\n",
      "  40. o3_lag_30\n",
      "  41. solar_radiation_lag_7\n",
      "  42. solar_radiation_lag_14\n",
      "  43. solar_radiation_lag_30\n",
      "  44. tb_case_roll_7\n",
      "  45. tb_case_roll_14\n",
      "  46. tb_case_roll_30\n",
      "  47. avg_temp_roll_7\n",
      "  48. avg_temp_roll_14\n",
      "  49. avg_temp_roll_30\n",
      "  50. humidity_roll_7\n",
      "  51. humidity_roll_14\n",
      "  52. humidity_roll_30\n",
      "  53. pm10_roll_7\n",
      "  54. pm10_roll_14\n",
      "  55. pm10_roll_30\n",
      "  56. precipitation_roll_7\n",
      "  57. precipitation_roll_14\n",
      "  58. precipitation_roll_30\n",
      "  59. solar_radiation_roll_7\n",
      "  60. solar_radiation_roll_14\n",
      "  61. solar_radiation_roll_30\n",
      "  62. avg_temp_roll_std_7\n",
      "  63. pm10_roll_std_7\n",
      "  64. humidity_roll_std_7\n",
      "  65. temp_humidity\n",
      "  66. pm10_humidity\n",
      "  67. temp_precipitation\n",
      "  68. temp_pm10\n",
      "  69. pollution_index\n",
      "  70. month\n",
      "  71. season\n",
      "\n",
      "✓ Reduced data saved to 'data/processed/tb_data_reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Remove Redundant Features\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: REMOVING REDUNDANT FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Features to remove\n",
    "features_to_remove = [\n",
    "    'temp_max',       # Keep only avg_temp\n",
    "    'temp_min',       # Keep only avg_temp\n",
    "    'aqi',            # Redundant with individual pollutants\n",
    "    'wind_pressure',  # Correlated with air_pressure\n",
    "    'air_pressure',   # Removing as per your decision\n",
    "    'wind_speed',     # Removing as per your decision\n",
    "    'pm25'            # Testing with PM10 instead\n",
    "]\n",
    "\n",
    "print(f\"-> Removing {len(features_to_remove)} features:\")\n",
    "for i, feature in enumerate(features_to_remove, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Create reduced dataframe\n",
    "df = df.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"\\n-> Features removed successfully!\")\n",
    "print(f\"\\nBefore: {df.shape[1]} columns\")\n",
    "print(f\"After:  {df_reduced.shape[1]} columns\")\n",
    "print(f\"Removed: {len(features_to_remove)} columns\")\n",
    "\n",
    "print(f\"\\nRemaining features ({df_reduced.shape[1]}):\")\n",
    "for i, col in enumerate(df_reduced.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Save reduced dataset\n",
    "df.to_csv('data/processed/tb_data_reduced.csv', index=False)\n",
    "print(f\"\\n✓ Reduced data saved to 'data/processed/tb_data_reduced.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe36c58-7b0c-419c-b51a-3288bd2bd07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df810206-a167-458a-8708-76e87ec7374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "Missing values:\n",
      "co           308\n",
      "nh3          308\n",
      "no2          308\n",
      "o3           308\n",
      "pm10         385\n",
      "so2          308\n",
      "tb_case    61964\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "district                   object\n",
      "date               datetime64[ns]\n",
      "co                        float64\n",
      "humidity                  float64\n",
      "nh3                       float64\n",
      "no2                       float64\n",
      "o3                        float64\n",
      "pm10                      float64\n",
      "precipitation             float64\n",
      "so2                       float64\n",
      "solar_radiation           float64\n",
      "tb_case                   float64\n",
      "avg_temp                  float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "  district       date      co  humidity   nh3   no2     o3    pm10  \\\n",
      "0   Achham 2021-01-01  699.56     31.65  4.48  4.61  41.96  106.54   \n",
      "1   Achham 2022-01-01  674.25     66.64  1.65  2.89  31.53   81.47   \n",
      "2   Achham 2023-01-01  602.20     75.08  2.26  3.26  55.30  110.48   \n",
      "3   Achham 2024-01-01  660.34     49.22  4.13  3.62  39.98  104.90   \n",
      "4   Achham 2021-10-01  379.26     78.97  1.27  1.85  12.56   21.64   \n",
      "\n",
      "   precipitation   so2  solar_radiation  tb_case  avg_temp  \n",
      "0           0.00  1.19             3.35      1.0     16.87  \n",
      "1           0.00  0.65             2.96      NaN     13.00  \n",
      "2           0.00  1.36             2.44      1.0     14.15  \n",
      "3           0.00  1.06             2.66      NaN     15.40  \n",
      "4           1.26  0.32             4.05      2.0     26.66  \n",
      "\n",
      "Basic statistics:\n",
      "                      date             co       humidity            nh3  \\\n",
      "count               112497  112189.000000  112497.000000  112189.000000   \n",
      "mean   2023-01-01 00:00:00     648.879823      67.166971       7.345359   \n",
      "min    2021-01-01 00:00:00      96.940000       6.530000       0.020000   \n",
      "25%    2022-01-01 00:00:00     356.730000      51.030000       1.660000   \n",
      "50%    2023-01-01 00:00:00     501.790000      71.600000       4.360000   \n",
      "75%    2024-01-01 00:00:00     737.110000      85.550000       9.150000   \n",
      "max    2024-12-31 00:00:00    8117.680000      99.760000     164.150000   \n",
      "std                    NaN     549.318139      20.639562       9.993657   \n",
      "\n",
      "                 no2             o3           pm10  precipitation  \\\n",
      "count  112189.000000  112189.000000  112112.000000  112497.000000   \n",
      "mean        5.015127      56.181157      65.109189       4.302973   \n",
      "min      -416.580000    -403.940000       0.550000       0.000000   \n",
      "25%         1.330000      39.260000      14.140000       0.000000   \n",
      "50%         2.950000      56.470000      37.530000       0.210000   \n",
      "75%         6.500000      71.600000      84.130000       4.270000   \n",
      "max       131.240000     203.830000    1009.750000     165.520000   \n",
      "std        17.639582      25.756311      78.807305       9.878226   \n",
      "\n",
      "                 so2  solar_radiation       tb_case       avg_temp  \n",
      "count  112189.000000    112497.000000  50533.000000  112497.000000  \n",
      "mean        2.373668         4.515886      2.720579      17.076049  \n",
      "min         0.000000         0.390000      1.000000     -24.230000  \n",
      "25%         0.460000         3.640000      1.000000      11.960000  \n",
      "50%         1.210000         4.420000      2.000000      18.130000  \n",
      "75%         2.630000         5.410000      4.000000      23.570000  \n",
      "max        82.020000         9.430000     66.000000      40.780000  \n",
      "std         4.144131         1.361215      2.479356       9.173739  \n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"-> No missing values\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# First few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9e114b5-ddf8-4b9a-b578-8942b9034edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HANDLING MISSING VALUES\n",
      "============================================================\n",
      "Total missing values: 63889\n",
      "\n",
      "Step 1: Forward filling (max 3 days)...\n",
      "Step 2: Backward filling (max 3 days)...\n",
      "Step 3: Linear interpolation...\n",
      "Step 4: Filling remaining with district median...\n",
      "\n",
      "-> Missing values handled!\n",
      "   Before: 63889\n",
      "   After: 0\n",
      "   Imputed: 63889\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"=\"*60)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check missing values\n",
    "missing_before = df.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    # Sort by district and date first\n",
    "    df = df.sort_values(['district', 'date'])\n",
    "    \n",
    "    # List of columns to impute\n",
    "    impute_cols = [col for col in df.columns if col not in ['district', 'date']]\n",
    "    \n",
    "    # Method 1: Forward fill (for time series) - max 3 days\n",
    "    print(\"\\nStep 1: Forward filling (max 3 days)...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].fillna(method='ffill', limit=3)\n",
    "    \n",
    "    # Method 2: Backward fill - max 3 days\n",
    "    print(\"Step 2: Backward filling (max 3 days)...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].fillna(method='bfill', limit=3)\n",
    "    \n",
    "    # Method 3: Linear interpolation\n",
    "    print(\"Step 3: Linear interpolation...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].transform(\n",
    "                lambda x: x.interpolate(method='linear', limit_direction='both')\n",
    "            )\n",
    "    \n",
    "    # Method 4: Fill remaining with median (by district)\n",
    "    print(\"Step 4: Filling remaining with district median...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "    \n",
    "    # Method 5: Fill any still-remaining with overall median (edge cases)\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    print(f\"\\n-> Missing values handled!\")\n",
    "    print(f\"   Before: {missing_before}\")\n",
    "    print(f\"   After: {missing_after}\")\n",
    "    print(f\"   Imputed: {missing_before - missing_after}\")\n",
    "else:\n",
    "    print(\"-> No missing values to handle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea56c0df-ab48-4260-a510-7a60fbf79294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: PREPARING FOR FEATURE ENGINEERING\n",
      "============================================================\n",
      "-> Data sorted by district and date\n",
      "\n",
      "Missing values before engineering: 0\n",
      "   After: 0\n",
      "\n",
      "Data ready for feature engineering!\n",
      "  Shape: (112497, 13)\n",
      "  Date range: 2021-01-01 00:00:00 to 2024-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Prepare for Feature Engineering (Sort by District and Date)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: PREPARING FOR FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by district and date for proper time series handling\n",
    "df = df.sort_values(['district', 'date']).reset_index(drop=True)\n",
    "print(\"-> Data sorted by district and date\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_before = df.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nMissing values before engineering: {missing_before}\")\n",
    "print(f\"   After: {missing_after}\")\n",
    "\n",
    "print(f\"\\nData ready for feature engineering!\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Date range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0cf5857a-7196-4a2c-a8a2-7cd61ae72098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: CREATING TIME LAG FEATURES\n",
      "============================================================\n",
      "-> Creating lag features for 10 variables\n",
      "   Lag periods: [7, 14, 30] days\n",
      "   Total lag features to create: 30\n",
      "\n",
      "✓ Created 30 lag features\n",
      "   New shape: (112497, 43)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: CREATING TIME LAG FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define lag periods (extending to 90 days / ~3 months)\n",
    "lag_periods = [ 7, 14, 30]\n",
    "\n",
    "# Variables to create lags for\n",
    "lag_variables = [\n",
    "    'tb_case', 'avg_temp', 'humidity', 'precipitation', \n",
    "    'pm10', 'so2', 'no2', 'co', 'o3', 'solar_radiation'\n",
    "]\n",
    "\n",
    "print(f\"-> Creating lag features for {len(lag_variables)} variables\")\n",
    "print(f\"   Lag periods: {lag_periods} days\")\n",
    "print(f\"   Total lag features to create: {len(lag_variables) * len(lag_periods)}\")\n",
    "\n",
    "# Create lag features\n",
    "for var in lag_variables:\n",
    "    for lag in lag_periods:\n",
    "        col_name = f'{var}_lag_{lag}'\n",
    "        df[col_name] = df.groupby('district')[var].shift(lag)\n",
    "        \n",
    "print(f\"\\n✓ Created {len(lag_variables) * len(lag_periods)} lag features\")\n",
    "print(f\"   New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dea67bac-7292-4691-b9b1-1ca1b5acd59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 4: CREATING ROLLING WINDOW FEATURES\n",
      "============================================================\n",
      "-> Creating rolling mean features\n",
      "   Windows: [7, 14, 30] days\n",
      "   Variables: 6\n",
      "\n",
      "✓ Created 18 rolling mean features\n",
      "\n",
      "-> Creating rolling std features (volatility indicators)\n",
      "✓ Created 3 rolling std features\n",
      "   New shape: (112497, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: CREATING ROLLING WINDOW FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define rolling windows\n",
    "rolling_windows = [ 7, 14, 30]\n",
    "\n",
    "# Variables for rolling features\n",
    "rolling_variables = [\n",
    "    'tb_case', 'avg_temp', 'humidity', 'pm10', \n",
    "    'precipitation', 'solar_radiation'\n",
    "]\n",
    "\n",
    "print(f\"-> Creating rolling mean features\")\n",
    "print(f\"   Windows: {rolling_windows} days\")\n",
    "print(f\"   Variables: {len(rolling_variables)}\")\n",
    "\n",
    "# Create rolling mean features\n",
    "for var in rolling_variables:\n",
    "    for window in rolling_windows:\n",
    "        col_name = f'{var}_roll_{window}'\n",
    "        df[col_name] = df.groupby('district')[var].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "\n",
    "print(f\"\\n✓ Created {len(rolling_variables) * len(rolling_windows)} rolling mean features\")\n",
    "\n",
    "# Create rolling standard deviation (volatility) features\n",
    "print(f\"\\n-> Creating rolling std features (volatility indicators)\")\n",
    "volatility_variables = ['avg_temp', 'pm10', 'humidity']\n",
    "volatility_window = 7\n",
    "\n",
    "for var in volatility_variables:\n",
    "    col_name = f'{var}_roll_std_{volatility_window}'\n",
    "    df[col_name] = df.groupby('district')[var].transform(\n",
    "        lambda x: x.rolling(window=volatility_window, min_periods=1).std()\n",
    "    )\n",
    "\n",
    "print(f\"✓ Created {len(volatility_variables)} rolling std features\")\n",
    "print(f\"   New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee266d0f-6fb6-4166-a29e-fef6e44d3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: CREATING INTERACTION FEATURES\n",
      "============================================================\n",
      "-> Creating interaction features...\n",
      "   ✓ temp_humidity (Temperature × Humidity)\n",
      "   ✓ pm10_humidity (PM10 × Humidity)\n",
      "   ✓ temp_precipitation (Temperature × Precipitation)\n",
      "   ✓ temp_pm10 (Temperature × PM10)\n",
      "   ✓ pollution_index (Composite pollution indicator)\n",
      "   ✓ month (Month number)\n",
      "   ✓ season (Seasonal category)\n",
      "\n",
      "✓ Created 7 interaction/derived features\n",
      "   New shape: (112497, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: CREATING INTERACTION FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"-> Creating interaction features...\")\n",
    "\n",
    "# Temperature × Humidity\n",
    "df['temp_humidity'] = df['avg_temp'] * df['humidity']\n",
    "print(\"   ✓ temp_humidity (Temperature × Humidity)\")\n",
    "\n",
    "# PM10 × Humidity\n",
    "df['pm10_humidity'] = df['pm10'] * df['humidity']\n",
    "print(\"   ✓ pm10_humidity (PM10 × Humidity)\")\n",
    "\n",
    "# Temperature × Precipitation\n",
    "df['temp_precipitation'] = df['avg_temp'] * df['precipitation']\n",
    "print(\"   ✓ temp_precipitation (Temperature × Precipitation)\")\n",
    "\n",
    "# Temperature × PM10\n",
    "df['temp_pm10'] = df['avg_temp'] * df['pm10']\n",
    "print(\"   ✓ temp_pm10 (Temperature × PM10)\")\n",
    "\n",
    "# Pollution composite index (normalized sum of pollutants)\n",
    "df['pollution_index'] = (\n",
    "    df['pm10'] / df['pm10'].max() +\n",
    "    df['no2'] / df['no2'].max() +\n",
    "    df['so2'] / df['so2'].max() +\n",
    "    df['co'] / df['co'].max() +\n",
    "    df['o3'] / df['o3'].max()\n",
    ") / 5\n",
    "print(\"   ✓ pollution_index (Composite pollution indicator)\")\n",
    "\n",
    "# Seasonal indicators (month-based)\n",
    "df['month'] = df['date'].dt.month\n",
    "df['season'] = df['month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "})\n",
    "print(\"   ✓ month (Month number)\")\n",
    "print(\"   ✓ season (Seasonal category)\")\n",
    "\n",
    "print(f\"\\n✓ Created 7 interaction/derived features\")\n",
    "print(f\"   New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77443e90-8f3c-4faf-b0a7-b92fdfe13b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: HANDLING OUTLIERS\n",
      "============================================================\n",
      "-> Capping outliers using IQR method (1.5 × IQR)\n",
      "   Variables to process: 11\n",
      "\n",
      "✓ Outliers capped for 11 variables\n",
      "\n",
      "Outlier Summary:\n",
      "       variable  outliers_capped  lower_bound  upper_bound\n",
      "        tb_case            15572       -0.500        3.500\n",
      "       avg_temp             2749       -5.455       40.985\n",
      "  precipitation            13889       -6.405       10.675\n",
      "           pm10             8218      -90.955      189.325\n",
      "            so2             9052       -2.795        5.885\n",
      "            no2             8912       -6.415       14.265\n",
      "             co             8714     -214.610     1308.590\n",
      "             o3              709       -9.380      120.140\n",
      "            nh3             7361       -9.590       20.410\n",
      "solar_radiation              821        0.985        8.065\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Handle Outliers (Capping Method)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: HANDLING OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Variables to cap outliers\n",
    "outlier_vars = [\n",
    "    'tb_case', 'avg_temp', 'humidity', 'precipitation',\n",
    "    'pm10', 'so2', 'no2', 'co', 'o3', 'nh3', 'solar_radiation'\n",
    "]\n",
    "\n",
    "print(f\"-> Capping outliers using IQR method (1.5 × IQR)\")\n",
    "print(f\"   Variables to process: {len(outlier_vars)}\")\n",
    "\n",
    "outlier_report = []\n",
    "\n",
    "for var in outlier_vars:\n",
    "    if var in df.columns:\n",
    "        # Calculate IQR\n",
    "        Q1 = df[var].quantile(0.25)\n",
    "        Q3 = df[var].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count outliers before capping\n",
    "        outliers_before = ((df[var] < lower_bound) | \n",
    "                          (df[var] > upper_bound)).sum()\n",
    "        \n",
    "        # Cap outliers\n",
    "        df[var] = df[var].clip(lower=lower_bound, upper=upper_bound)\n",
    "        \n",
    "        if outliers_before > 0:\n",
    "            outlier_report.append({\n",
    "                'variable': var,\n",
    "                'outliers_capped': outliers_before,\n",
    "                'lower_bound': lower_bound,\n",
    "                'upper_bound': upper_bound\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Outliers capped for {len(outlier_vars)} variables\")\n",
    "\n",
    "if outlier_report:\n",
    "    print(f\"\\nOutlier Summary:\")\n",
    "    outlier_df = pd.DataFrame(outlier_report)\n",
    "    print(outlier_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n   No outliers found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63608cf8-3bb9-4f97-b288-5149a27ae53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 7: HANDLING MISSING VALUES\n",
      "============================================================\n",
      "-> Missing values found in 33 columns\n",
      "\n",
      "Top 10 columns with missing values:\n",
      "tb_case_lag_30            2310\n",
      "o3_lag_30                 2310\n",
      "avg_temp_lag_30           2310\n",
      "humidity_lag_30           2310\n",
      "precipitation_lag_30      2310\n",
      "pm10_lag_30               2310\n",
      "co_lag_30                 2310\n",
      "no2_lag_30                2310\n",
      "so2_lag_30                2310\n",
      "solar_radiation_lag_30    2310\n",
      "dtype: int64\n",
      "\n",
      "-> Dropped 2,310 rows with missing values (2.05%)\n",
      "   Remaining rows: 110,187\n",
      "\n",
      "✓ Final missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Remove Rows with Missing Values from Lag Features\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: HANDLING MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_vars = missing_counts[missing_counts > 0]\n",
    "\n",
    "print(f\"-> Missing values found in {len(missing_vars)} columns\")\n",
    "if len(missing_vars) > 0:\n",
    "    print(f\"\\nTop 10 columns with missing values:\")\n",
    "    print(missing_vars.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Drop rows with missing values (from lag features)\n",
    "\n",
    "max_lag = 30\n",
    "\n",
    "rows_before = len(df)\n",
    "df = df.groupby('district').apply(lambda g: g.iloc[max_lag:]).reset_index(drop=True)\n",
    "rows_after = len(df)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"\\n-> Dropped {rows_dropped:,} rows with missing values ({rows_dropped/rows_before*100:.2f}%)\")\n",
    "print(f\"   Remaining rows: {rows_after:,}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "final_missing = df.isnull().sum().sum()\n",
    "print(f\"\\n✓ Final missing values: {final_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb73bc7e-2bc5-419d-bb6a-7ec3a33b03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE - FINAL SUMMARY\n",
      "======================================================================\n",
      "Final shape: (110187, 71)\n",
      "  Rows: 110,187\n",
      "  Columns: 71\n",
      "\n",
      "Date range: 2021-01-31 00:00:00 to 2024-12-31 00:00:00\n",
      "Total days: 1430\n",
      "Number of districts: 77\n",
      "\n",
      "Feature categories:\n",
      "  Original features: 20\n",
      "  Temporal features: 2\n",
      "  Lagged features: 30\n",
      "  Rolling features: 21\n",
      "  Interaction features: 5\n",
      "  TOTAL: 71\n",
      "\n",
      "Missing values: 0\n",
      "\n",
      "Column names:\n",
      "   1. district\n",
      "   2. date\n",
      "   3. co\n",
      "   4. humidity\n",
      "   5. nh3\n",
      "   6. no2\n",
      "   7. o3\n",
      "   8. pm10\n",
      "   9. precipitation\n",
      "  10. so2\n",
      "  11. solar_radiation\n",
      "  12. tb_case\n",
      "  13. avg_temp\n",
      "  14. tb_case_lag_7\n",
      "  15. tb_case_lag_14\n",
      "  16. tb_case_lag_30\n",
      "  17. avg_temp_lag_7\n",
      "  18. avg_temp_lag_14\n",
      "  19. avg_temp_lag_30\n",
      "  20. humidity_lag_7\n",
      "  21. humidity_lag_14\n",
      "  22. humidity_lag_30\n",
      "  23. precipitation_lag_7\n",
      "  24. precipitation_lag_14\n",
      "  25. precipitation_lag_30\n",
      "  26. pm10_lag_7\n",
      "  27. pm10_lag_14\n",
      "  28. pm10_lag_30\n",
      "  29. so2_lag_7\n",
      "  30. so2_lag_14\n",
      "  31. so2_lag_30\n",
      "  32. no2_lag_7\n",
      "  33. no2_lag_14\n",
      "  34. no2_lag_30\n",
      "  35. co_lag_7\n",
      "  36. co_lag_14\n",
      "  37. co_lag_30\n",
      "  38. o3_lag_7\n",
      "  39. o3_lag_14\n",
      "  40. o3_lag_30\n",
      "  41. solar_radiation_lag_7\n",
      "  42. solar_radiation_lag_14\n",
      "  43. solar_radiation_lag_30\n",
      "  44. tb_case_roll_7\n",
      "  45. tb_case_roll_14\n",
      "  46. tb_case_roll_30\n",
      "  47. avg_temp_roll_7\n",
      "  48. avg_temp_roll_14\n",
      "  49. avg_temp_roll_30\n",
      "  50. humidity_roll_7\n",
      "  51. humidity_roll_14\n",
      "  52. humidity_roll_30\n",
      "  53. pm10_roll_7\n",
      "  54. pm10_roll_14\n",
      "  55. pm10_roll_30\n",
      "  56. precipitation_roll_7\n",
      "  57. precipitation_roll_14\n",
      "  58. precipitation_roll_30\n",
      "  59. solar_radiation_roll_7\n",
      "  60. solar_radiation_roll_14\n",
      "  61. solar_radiation_roll_30\n",
      "  62. avg_temp_roll_std_7\n",
      "  63. pm10_roll_std_7\n",
      "  64. humidity_roll_std_7\n",
      "  65. temp_humidity\n",
      "  66. pm10_humidity\n",
      "  67. temp_precipitation\n",
      "  68. temp_pm10\n",
      "  69. pollution_index\n",
      "  70. month\n",
      "  71. season\n",
      "\n",
      "Data types:\n",
      "float64           67\n",
      "object             2\n",
      "datetime64[ns]     1\n",
      "int32              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Memory usage:\n",
      "  69.26 MB\n"
     ]
    }
   ],
   "source": [
    "# Summary of processed data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"  Rows: {df.shape[0]:,}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Total days: {(df['date'].max() - df['date'].min()).days}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")\n",
    "\n",
    "# Define feature categories\n",
    "temporal_features = ['year', 'month', 'day', 'day_of_week', 'week_of_year', \n",
    "                    'quarter', 'season', 'day_of_year', 'month_sin', 'month_cos', \n",
    "                    'day_sin', 'day_cos']\n",
    "\n",
    "interaction_features = ['temp_humidity', 'pm10_humidity', 'temp_precipitation',\n",
    "                        'temp_range', 'pollution_index', 'temp_pm10', 'wind_pm10']\n",
    "\n",
    "# Count features\n",
    "lagged_features = [col for col in df.columns if 'lag' in col]\n",
    "rolling_features = [col for col in df.columns if 'roll' in col]\n",
    "temporal_in_df = [col for col in df.columns if col in temporal_features]\n",
    "interaction_in_df = [col for col in df.columns if col in interaction_features]\n",
    "\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"  Original features: 20\")\n",
    "print(f\"  Temporal features: {len(temporal_in_df)}\")\n",
    "print(f\"  Lagged features: {len(lagged_features)}\")\n",
    "print(f\"  Rolling features: {len(rolling_features)}\")\n",
    "print(f\"  Interaction features: {len(interaction_in_df)}\")\n",
    "print(f\"  TOTAL: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(f\"  {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10453c07-3a36-4bcc-b9fd-b64bb166b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed data saved to: data/processed/tb_data_processed.csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "output_path = 'data/processed/tb_data_processed.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Processed data saved to: {output_path}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8c124-fdf9-4ddf-bcca-9dc909b855dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
