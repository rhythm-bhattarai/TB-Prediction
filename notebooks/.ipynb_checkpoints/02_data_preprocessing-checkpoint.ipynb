{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8292bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIAL DATA INSPECTION\n",
      "============================================================\n",
      "Shape: (112497, 20)\n",
      "\n",
      "Column names (RAW):\n",
      "0: 'District'\n",
      "1: 'Date'\n",
      "2: 'AQI'\n",
      "3: 'CO '\n",
      "4: 'Humidity'\n",
      "5: 'NH3'\n",
      "6: 'NO2 '\n",
      "7: 'O3 '\n",
      "8: 'PM10 '\n",
      "9: 'PM2.5'\n",
      "10: 'Precipitation '\n",
      "11: 'Air Pressure'\n",
      "12: 'SO2'\n",
      "13: 'Solar Radiation'\n",
      "14: 'TB Case'\n",
      "15: 'Avg Temp'\n",
      "16: 'Temp Max '\n",
      "17: 'Temp Min '\n",
      "18: 'Wind Pressure'\n",
      "19: 'Wind Speed'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/raw/tb_climate_data.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATA INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names (RAW):\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i}: '{col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7fae1f-bf17-4cac-ad30-292625e57c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING COLUMN NAMES\n",
      "============================================================\n",
      "BEFORE cleaning:\n",
      "['District', 'Date', 'AQI', 'CO ', 'Humidity', 'NH3', 'NO2 ', 'O3 ', 'PM10 ', 'PM2.5', 'Precipitation ', 'Air Pressure', 'SO2', 'Solar Radiation', 'TB Case', 'Avg Temp', 'Temp Max ', 'Temp Min ', 'Wind Pressure', 'Wind Speed']\n",
      "\n",
      "AFTER cleaning:\n",
      "['District', 'Date', 'AQI', 'CO', 'Humidity', 'NH3', 'NO2', 'O3', 'PM10', 'PM2.5', 'Precipitation', 'Air Pressure', 'SO2', 'Solar Radiation', 'TB Case', 'Avg Temp', 'Temp Max', 'Temp Min', 'Wind Pressure', 'Wind Speed']\n",
      "\n",
      "Checking specific columns:\n",
      "-> 'Temp Max' found\n",
      "-> 'Temp Min' found\n",
      "-> 'TB Case' found\n",
      "-> 'Avg Temp' found\n"
     ]
    }
   ],
   "source": [
    "# clean column names\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLEANING COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show before\n",
    "print(\"BEFORE cleaning:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Strip whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Show after\n",
    "print(\"\\nAFTER cleaning:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Verify specific columns\n",
    "test_cols = ['Temp Max', 'Temp Min', 'TB Case', 'Avg Temp']\n",
    "print(f\"\\nChecking specific columns:\")\n",
    "for col in test_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"-> '{col}' found\")\n",
    "    else:\n",
    "        print(f\"* '{col}' NOT found\")\n",
    "        # Find similar names\n",
    "        similar = [c for c in df.columns if col.lower() in c.lower()]\n",
    "        if similar:\n",
    "            print(f\"   Similar names found: {similar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf1b9cc-5f9d-4354-b31b-19a21ee39f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA TYPES INSPECTION\n",
      "============================================================\n",
      "District            object\n",
      "Date                object\n",
      "AQI                float64\n",
      "CO                 float64\n",
      "Humidity           float64\n",
      "NH3                float64\n",
      "NO2                float64\n",
      "O3                 float64\n",
      "PM10               float64\n",
      "PM2.5              float64\n",
      "Precipitation      float64\n",
      "Air Pressure       float64\n",
      "SO2                float64\n",
      "Solar Radiation    float64\n",
      "TB Case            float64\n",
      "Avg Temp           float64\n",
      "Temp Max           float64\n",
      "Temp Min           float64\n",
      "Wind Pressure      float64\n",
      "Wind Speed         float64\n",
      "dtype: object\n",
      "\n",
      "Checking for non-numeric values in numeric columns:\n",
      "\n",
      "District:\n",
      "  Sample values: ['Achham', 'Achham', 'Achham', 'Achham', 'Achham']\n",
      "  * Contains non-numeric values: ['Achham' 'Arghakhanchi' 'Baglung' 'Baitadi' 'Bajhang']\n",
      "\n",
      "Date:\n",
      "  Sample values: ['1/1/2021', '2/1/2021', '3/1/2021', '4/1/2021', '5/1/2021']\n",
      "  * Contains non-numeric values: ['1/1/2021' '2/1/2021' '3/1/2021' '4/1/2021' '5/1/2021']\n"
     ]
    }
   ],
   "source": [
    "# check and fix data types\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA TYPES INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any columns that should be numeric but aren't\n",
    "print(\"\\nChecking for non-numeric values in numeric columns:\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['district', 'date']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Sample values: {df[col].head().tolist()}\")\n",
    "    \n",
    "    # Try to find non-numeric values\n",
    "    try:\n",
    "        pd.to_numeric(df[col])\n",
    "        print(f\"  -> Can be converted to numeric\")\n",
    "    except:\n",
    "        non_numeric = df[~df[col].apply(lambda x: str(x).replace('.','').replace('-','').isdigit())]\n",
    "        print(f\"  * Contains non-numeric values: {non_numeric[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292acab0-8e5a-45b0-b1e8-40cc593286fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STANDARDIZING COLUMN NAMES\n",
      "============================================================\n",
      "Column names standardized:\n",
      "['district', 'date', 'aqi', 'co', 'humidity', 'nh3', 'no2', 'o3', 'pm10', 'pm25', 'precipitation', 'air_pressure', 'so2', 'solar_radiation', 'tb_case', 'avg_temp', 'temp_max', 'temp_min', 'wind_pressure', 'wind_speed']\n"
     ]
    }
   ],
   "source": [
    "# standardize column names\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STANDARDIZING COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a mapping dictionary for cleaner, consistent names\n",
    "column_mapping = {\n",
    "    'District': 'district',\n",
    "    'Date': 'date',\n",
    "    'AQI': 'aqi',\n",
    "    'CO': 'co',\n",
    "    'Humidity': 'humidity',\n",
    "    'NH3': 'nh3',\n",
    "    'NO2': 'no2',\n",
    "    'O3': 'o3',\n",
    "    'PM10': 'pm10',\n",
    "    'PM2.5': 'pm25',\n",
    "    'Precipitation': 'precipitation',\n",
    "    'Air Pressure': 'air_pressure',\n",
    "    'SO2': 'so2',\n",
    "    'Solar Radiation': 'solar_radiation',\n",
    "    'TB Case': 'tb_case',\n",
    "    'Avg Temp': 'avg_temp',\n",
    "    'Temp Max': 'temp_max',\n",
    "    'Temp Min': 'temp_min',\n",
    "    'Wind Pressure': 'wind_pressure',\n",
    "    'Wind Speed': 'wind_speed'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "print(\"Column names standardized:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71dae90a-739f-4d3e-bb69-fc481b87b92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA TYPES INSPECTION\n",
      "============================================================\n",
      "district            object\n",
      "date                object\n",
      "aqi                float64\n",
      "co                 float64\n",
      "humidity           float64\n",
      "nh3                float64\n",
      "no2                float64\n",
      "o3                 float64\n",
      "pm10               float64\n",
      "pm25               float64\n",
      "precipitation      float64\n",
      "air_pressure       float64\n",
      "so2                float64\n",
      "solar_radiation    float64\n",
      "tb_case            float64\n",
      "avg_temp           float64\n",
      "temp_max           float64\n",
      "temp_min           float64\n",
      "wind_pressure      float64\n",
      "wind_speed         float64\n",
      "dtype: object\n",
      "\n",
      "Checking for non-numeric values in numeric columns:\n"
     ]
    }
   ],
   "source": [
    "# check and fix data types\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA TYPES INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any columns that should be numeric but aren't\n",
    "print(\"\\nChecking for non-numeric values in numeric columns:\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['district', 'date']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Sample values: {df[col].head().tolist()}\")\n",
    "    \n",
    "    # Try to find non-numeric values\n",
    "    try:\n",
    "        pd.to_numeric(df[col])\n",
    "        print(f\"  -> Can be converted to numeric\")\n",
    "    except:\n",
    "        non_numeric = df[~df[col].apply(lambda x: str(x).replace('.','').replace('-','').isdigit())]\n",
    "        print(f\"  * Contains non-numeric values: {non_numeric[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd65f179-b01d-4524-841a-eb92736a521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKING FOR DUPLICATES\n",
      "============================================================\n",
      "Complete duplicate rows: 0\n",
      "\n",
      "Duplicate (district, date) combinations: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING FOR DUPLICATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for complete duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Complete duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Removing duplicates...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"-> {duplicates} duplicate rows removed\")\n",
    "\n",
    "# Check for duplicates based on district and date\n",
    "duplicate_keys = df.duplicated(subset=['district', 'date']).sum()\n",
    "print(f\"\\nDuplicate (district, date) combinations: {duplicate_keys}\")\n",
    "\n",
    "if duplicate_keys > 0:\n",
    "    print(\"# Warning: Multiple entries for same district and date\")\n",
    "    print(\"Sample duplicates:\")\n",
    "    print(df[df.duplicated(subset=['district', 'date'], keep=False)].head(10))\n",
    "    \n",
    "    # Option 1: Keep first occurrence\n",
    "    # df = df.drop_duplicates(subset=['district', 'date'], keep='first')\n",
    "    \n",
    "    # Option 2: Average the values (better for numeric data)\n",
    "    print(\"\\nAveraging duplicate entries...\")\n",
    "    df = df.groupby(['district', 'date'], as_index=False).mean()\n",
    "    print(f\"-> Duplicates averaged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b993419-71fd-41b8-a919-4907a0d2481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKING FOR INVALID VALUES\n",
      "============================================================\n",
      "# pm10: 77 negative values found\n",
      "   Min value: -415.31\n",
      "   -> Negative values replaced with NaN\n",
      "\n",
      "Checking for extreme outliers:\n"
     ]
    }
   ],
   "source": [
    "# check for invalid values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING FOR INVALID VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for negative values where they shouldn't exist\n",
    "check_positive = ['tb_case', 'pm25', 'pm10', 'aqi', 'humidity', 'precipitation']\n",
    "\n",
    "for col in check_positive:\n",
    "    if col in df.columns:\n",
    "        negative_count = (df[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"# {col}: {negative_count} negative values found\")\n",
    "            print(f\"   Min value: {df[col].min()}\")\n",
    "            # Replace negative with NaN (will be imputed later)\n",
    "            df.loc[df[col] < 0, col] = np.nan\n",
    "            print(f\"   -> Negative values replaced with NaN\")\n",
    "\n",
    "# Check for unrealistic values (outliers)\n",
    "print(\"\\nChecking for extreme outliers:\")\n",
    "\n",
    "# Example: Temperature should be reasonable (-50 to 50°C)\n",
    "if 'avg_temp' in df.columns:\n",
    "    extreme_temp = ((df['avg_temp'] < -50) | (df['avg_temp'] > 50)).sum()\n",
    "    if extreme_temp > 0:\n",
    "        print(f\"# avg_temp: {extreme_temp} extreme values found\")\n",
    "\n",
    "# Humidity should be 0-100%\n",
    "if 'humidity' in df.columns:\n",
    "    extreme_humidity = ((df['humidity'] < 0) | (df['humidity'] > 100)).sum()\n",
    "    if extreme_humidity > 0:\n",
    "        print(f\"# humidity: {extreme_humidity} values outside 0-100% range\")\n",
    "        df.loc[(df['humidity'] < 0) | (df['humidity'] > 100), 'humidity'] = np.nan\n",
    "        print(f\"   -> Invalid values replaced with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271ee068-419f-4545-bbb9-4d3a07c04460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SORTING DATA\n",
      "============================================================\n",
      "✅ Data sorted by district and date\n",
      "\n",
      "Date range: 1/1/2021 to 9/9/2024\n",
      "Number of districts: 77\n"
     ]
    }
   ],
   "source": [
    "# sorting data properly\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SORTING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by district and date\n",
    "df = df.sort_values(['district', 'date'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Data sorted by district and date\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c183f69a-e44a-4a00-81ac-d38441014c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA CLEANING SUMMARY\n",
      "======================================================================\n",
      "Final shape: (112497, 20)\n",
      "\n",
      "Column names (cleaned):\n",
      "   0. district\n",
      "   1. date\n",
      "   2. aqi\n",
      "   3. co\n",
      "   4. humidity\n",
      "   5. nh3\n",
      "   6. no2\n",
      "   7. o3\n",
      "   8. pm10\n",
      "   9. pm25\n",
      "  10. precipitation\n",
      "  11. air_pressure\n",
      "  12. so2\n",
      "  13. solar_radiation\n",
      "  14. tb_case\n",
      "  15. avg_temp\n",
      "  16. temp_max\n",
      "  17. temp_min\n",
      "  18. wind_pressure\n",
      "  19. wind_speed\n",
      "\n",
      "Data types:\n",
      "district            object\n",
      "date                object\n",
      "aqi                float64\n",
      "co                 float64\n",
      "humidity           float64\n",
      "nh3                float64\n",
      "no2                float64\n",
      "o3                 float64\n",
      "pm10               float64\n",
      "pm25               float64\n",
      "precipitation      float64\n",
      "air_pressure       float64\n",
      "so2                float64\n",
      "solar_radiation    float64\n",
      "tb_case            float64\n",
      "avg_temp           float64\n",
      "temp_max           float64\n",
      "temp_min           float64\n",
      "wind_pressure      float64\n",
      "wind_speed         float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "aqi          308\n",
      "co           308\n",
      "nh3          308\n",
      "no2          308\n",
      "o3           308\n",
      "pm10         385\n",
      "pm25         308\n",
      "so2          308\n",
      "tb_case    61964\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "                 aqi             co       humidity            nh3  \\\n",
      "count  112189.000000  112189.000000  112497.000000  112189.000000   \n",
      "mean        3.059435     648.879823      67.166971       7.345359   \n",
      "std         1.459724     549.318139      20.639562       9.993657   \n",
      "min         1.000000      96.940000       6.530000       0.020000   \n",
      "25%         2.000000     356.730000      51.030000       1.660000   \n",
      "50%         3.000000     501.790000      71.600000       4.360000   \n",
      "75%         5.000000     737.110000      85.550000       9.150000   \n",
      "max         5.000000    8117.680000      99.760000     164.150000   \n",
      "\n",
      "                 no2             o3           pm10          pm25  \\\n",
      "count  112189.000000  112189.000000  112112.000000  112189.00000   \n",
      "mean        5.015127      56.181157      65.109189      51.50960   \n",
      "std        17.639582      25.756311      78.807305      65.67648   \n",
      "min      -416.580000    -403.940000       0.550000       0.50000   \n",
      "25%         1.330000      39.260000      14.140000      10.82000   \n",
      "50%         2.950000      56.470000      37.530000      28.05000   \n",
      "75%         6.500000      71.600000      84.130000      64.90000   \n",
      "max       131.240000     203.830000    1009.750000     876.17000   \n",
      "\n",
      "       precipitation   air_pressure            so2  solar_radiation  \\\n",
      "count  112497.000000  112497.000000  112189.000000    112497.000000   \n",
      "mean        4.302973      84.888671       2.373668         4.515886   \n",
      "std         9.878226      11.441841       4.144131         1.361215   \n",
      "min         0.000000      54.220000       0.000000         0.390000   \n",
      "25%         0.000000      78.930000       0.460000         3.640000   \n",
      "50%         0.210000      87.530000       1.210000         4.420000   \n",
      "75%         4.270000      96.020000       2.630000         5.410000   \n",
      "max       165.520000     101.260000      82.020000         9.430000   \n",
      "\n",
      "            tb_case       avg_temp       temp_max       temp_min  \\\n",
      "count  50533.000000  112497.000000  112497.000000  112497.000000   \n",
      "mean       2.720579      17.076049      22.369275      12.874796   \n",
      "std        2.479356       9.173739       8.882772       9.452564   \n",
      "min        1.000000     -24.230000     -14.200000     -34.500000   \n",
      "25%        1.000000      11.960000      17.350000       7.710000   \n",
      "50%        2.000000      18.130000      23.180000      14.000000   \n",
      "75%        4.000000      23.570000      28.240000      20.080000   \n",
      "max       66.000000      40.780000      48.270000      33.980000   \n",
      "\n",
      "       wind_pressure     wind_speed  \n",
      "count  112497.000000  112497.000000  \n",
      "mean        1.768945       1.612539  \n",
      "std         1.419338       0.536169  \n",
      "min         0.080000       0.370000  \n",
      "25%         0.940000       1.240000  \n",
      "50%         1.430000       1.530000  \n",
      "75%         2.120000       1.860000  \n",
      "max        32.730000       7.310000  \n",
      "\n",
      "✅ Cleaned data saved to 'data/processed/tb_data_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"\\nColumn names (cleaned):\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No missing values\")\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# save cleaned data\n",
    "df.to_csv('data/processed/tb_data_cleaned.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved to 'data/processed/tb_data_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f783f981-d0b5-4bc6-9142-0d80d1f35433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# clean data import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"-> Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bbc3cc-76d1-4629-b516-7f9ab1143484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANED DATA LOADED\n",
      "============================================================\n",
      "Shape: (112497, 20)\n",
      "\n",
      "Date range: 2021-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Number of districts: 77\n",
      "\n",
      "Columns (20):\n",
      "['district', 'date', 'aqi', 'co', 'humidity', 'nh3', 'no2', 'o3', 'pm10', 'pm25', 'precipitation', 'air_pressure', 'so2', 'solar_radiation', 'tb_case', 'avg_temp', 'temp_max', 'temp_min', 'wind_pressure', 'wind_speed']\n",
      "\n",
      "-> Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load CLEANED data\n",
    "df = pd.read_csv('data/processed/tb_data_cleaned.csv')\n",
    "\n",
    "# Convert date to datetime (just in case)\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst = True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLEANED DATA LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")\n",
    "print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n-> Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558c6619-876e-4258-a77d-ba5a7f3104ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: REMOVING REDUNDANT FEATURES\n",
      "============================================================\n",
      "-> Removing 7 features:\n",
      "   1. temp_max\n",
      "   2. temp_min\n",
      "   3. aqi\n",
      "   4. wind_pressure\n",
      "   5. air_pressure\n",
      "   6. wind_speed\n",
      "   7. pm25\n",
      "\n",
      "-> Features removed successfully!\n",
      "\n",
      "Before: 20 columns\n",
      "After:  13 columns\n",
      "Removed: 7 columns\n",
      "\n",
      "Remaining features (13):\n",
      "   1. district\n",
      "   2. date\n",
      "   3. co\n",
      "   4. humidity\n",
      "   5. nh3\n",
      "   6. no2\n",
      "   7. o3\n",
      "   8. pm10\n",
      "   9. precipitation\n",
      "  10. so2\n",
      "  11. solar_radiation\n",
      "  12. tb_case\n",
      "  13. avg_temp\n",
      "\n",
      "✓ Reduced data saved to 'data/processed/tb_data_reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Remove Redundant Features\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: REMOVING REDUNDANT FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Features to remove\n",
    "features_to_remove = [\n",
    "    'temp_max',       # Keep only avg_temp\n",
    "    'temp_min',       # Keep only avg_temp\n",
    "    'aqi',            # Redundant with individual pollutants\n",
    "    'wind_pressure',  # Correlated with air_pressure\n",
    "    'air_pressure',   # Removing as per your decision\n",
    "    'wind_speed',     # Removing as per your decision\n",
    "    'pm25'            # Testing with PM10 instead\n",
    "]\n",
    "\n",
    "print(f\"-> Removing {len(features_to_remove)} features:\")\n",
    "for i, feature in enumerate(features_to_remove, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Create reduced dataframe\n",
    "df_reduced = df.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"\\n-> Features removed successfully!\")\n",
    "print(f\"\\nBefore: {df.shape[1]} columns\")\n",
    "print(f\"After:  {df_reduced.shape[1]} columns\")\n",
    "print(f\"Removed: {len(features_to_remove)} columns\")\n",
    "\n",
    "print(f\"\\nRemaining features ({df_reduced.shape[1]}):\")\n",
    "for i, col in enumerate(df_reduced.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Save reduced dataset\n",
    "df_reduced.to_csv('data/processed/tb_data_reduced.csv', index=False)\n",
    "print(f\"\\n✓ Reduced data saved to 'data/processed/tb_data_reduced.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe36c58-7b0c-419c-b51a-3288bd2bd07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df810206-a167-458a-8708-76e87ec7374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "Missing values:\n",
      "aqi          308\n",
      "co           308\n",
      "nh3          308\n",
      "no2          308\n",
      "o3           308\n",
      "pm10         385\n",
      "pm25         308\n",
      "so2          308\n",
      "tb_case    61964\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "district                   object\n",
      "date               datetime64[ns]\n",
      "aqi                       float64\n",
      "co                        float64\n",
      "humidity                  float64\n",
      "nh3                       float64\n",
      "no2                       float64\n",
      "o3                        float64\n",
      "pm10                      float64\n",
      "pm25                      float64\n",
      "precipitation             float64\n",
      "air_pressure              float64\n",
      "so2                       float64\n",
      "solar_radiation           float64\n",
      "tb_case                   float64\n",
      "avg_temp                  float64\n",
      "temp_max                  float64\n",
      "temp_min                  float64\n",
      "wind_pressure             float64\n",
      "wind_speed                float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "  district       date  aqi      co  humidity   nh3   no2     o3    pm10  \\\n",
      "0   Achham 2021-01-01  5.0  699.56     31.65  4.48  4.61  41.96  106.54   \n",
      "1   Achham 2022-01-01  5.0  674.25     66.64  1.65  2.89  31.53   81.47   \n",
      "2   Achham 2023-01-01  5.0  602.20     75.08  2.26  3.26  55.30  110.48   \n",
      "3   Achham 2024-01-01  5.0  660.34     49.22  4.13  3.62  39.98  104.90   \n",
      "4   Achham 2021-10-01  2.0  379.26     78.97  1.27  1.85  12.56   21.64   \n",
      "\n",
      "    pm25  precipitation  air_pressure   so2  solar_radiation  tb_case  \\\n",
      "0  85.15           0.00         96.96  1.19             3.35      1.0   \n",
      "1  64.79           0.00         97.39  0.65             2.96      NaN   \n",
      "2  94.67           0.00         97.30  1.36             2.44      1.0   \n",
      "3  83.93           0.00         97.06  1.06             2.66      NaN   \n",
      "4  13.56           1.26         96.32  0.32             4.05      2.0   \n",
      "\n",
      "   avg_temp  temp_max  temp_min  wind_pressure  wind_speed  \n",
      "0     16.87     24.53     12.04           0.74        1.10  \n",
      "1     13.00     18.90      9.34           1.04        1.30  \n",
      "2     14.15     19.38     10.61           0.66        1.04  \n",
      "3     15.40     21.98     11.90           0.84        1.17  \n",
      "4     26.66     29.34     22.68           0.49        0.89  \n",
      "\n",
      "Basic statistics:\n",
      "                      date            aqi             co       humidity  \\\n",
      "count               112497  112189.000000  112189.000000  112497.000000   \n",
      "mean   2023-01-01 00:00:00       3.059435     648.879823      67.166971   \n",
      "min    2021-01-01 00:00:00       1.000000      96.940000       6.530000   \n",
      "25%    2022-01-01 00:00:00       2.000000     356.730000      51.030000   \n",
      "50%    2023-01-01 00:00:00       3.000000     501.790000      71.600000   \n",
      "75%    2024-01-01 00:00:00       5.000000     737.110000      85.550000   \n",
      "max    2024-12-31 00:00:00       5.000000    8117.680000      99.760000   \n",
      "std                    NaN       1.459724     549.318139      20.639562   \n",
      "\n",
      "                 nh3            no2             o3           pm10  \\\n",
      "count  112189.000000  112189.000000  112189.000000  112112.000000   \n",
      "mean        7.345359       5.015127      56.181157      65.109189   \n",
      "min         0.020000    -416.580000    -403.940000       0.550000   \n",
      "25%         1.660000       1.330000      39.260000      14.140000   \n",
      "50%         4.360000       2.950000      56.470000      37.530000   \n",
      "75%         9.150000       6.500000      71.600000      84.130000   \n",
      "max       164.150000     131.240000     203.830000    1009.750000   \n",
      "std         9.993657      17.639582      25.756311      78.807305   \n",
      "\n",
      "               pm25  precipitation   air_pressure            so2  \\\n",
      "count  112189.00000  112497.000000  112497.000000  112189.000000   \n",
      "mean       51.50960       4.302973      84.888671       2.373668   \n",
      "min         0.50000       0.000000      54.220000       0.000000   \n",
      "25%        10.82000       0.000000      78.930000       0.460000   \n",
      "50%        28.05000       0.210000      87.530000       1.210000   \n",
      "75%        64.90000       4.270000      96.020000       2.630000   \n",
      "max       876.17000     165.520000     101.260000      82.020000   \n",
      "std        65.67648       9.878226      11.441841       4.144131   \n",
      "\n",
      "       solar_radiation       tb_case       avg_temp       temp_max  \\\n",
      "count    112497.000000  50533.000000  112497.000000  112497.000000   \n",
      "mean          4.515886      2.720579      17.076049      22.369275   \n",
      "min           0.390000      1.000000     -24.230000     -14.200000   \n",
      "25%           3.640000      1.000000      11.960000      17.350000   \n",
      "50%           4.420000      2.000000      18.130000      23.180000   \n",
      "75%           5.410000      4.000000      23.570000      28.240000   \n",
      "max           9.430000     66.000000      40.780000      48.270000   \n",
      "std           1.361215      2.479356       9.173739       8.882772   \n",
      "\n",
      "            temp_min  wind_pressure     wind_speed  \n",
      "count  112497.000000  112497.000000  112497.000000  \n",
      "mean       12.874796       1.768945       1.612539  \n",
      "min       -34.500000       0.080000       0.370000  \n",
      "25%         7.710000       0.940000       1.240000  \n",
      "50%        14.000000       1.430000       1.530000  \n",
      "75%        20.080000       2.120000       1.860000  \n",
      "max        33.980000      32.730000       7.310000  \n",
      "std         9.452564       1.419338       0.536169  \n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"-> No missing values\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# First few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e114b5-ddf8-4b9a-b578-8942b9034edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HANDLING MISSING VALUES\n",
      "============================================================\n",
      "Total missing values: 64505\n",
      "\n",
      "Step 1: Forward filling (max 3 days)...\n",
      "Step 2: Backward filling (max 3 days)...\n",
      "Step 3: Linear interpolation...\n",
      "Step 4: Filling remaining with district median...\n",
      "\n",
      "-> Missing values handled!\n",
      "   Before: 64505\n",
      "   After: 0\n",
      "   Imputed: 64505\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"=\"*60)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check missing values\n",
    "missing_before = df.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    # Sort by district and date first\n",
    "    df = df.sort_values(['district', 'date'])\n",
    "    \n",
    "    # List of columns to impute\n",
    "    impute_cols = [col for col in df.columns if col not in ['district', 'date']]\n",
    "    \n",
    "    # Method 1: Forward fill (for time series) - max 3 days\n",
    "    print(\"\\nStep 1: Forward filling (max 3 days)...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].fillna(method='ffill', limit=3)\n",
    "    \n",
    "    # Method 2: Backward fill - max 3 days\n",
    "    print(\"Step 2: Backward filling (max 3 days)...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].fillna(method='bfill', limit=3)\n",
    "    \n",
    "    # Method 3: Linear interpolation\n",
    "    print(\"Step 3: Linear interpolation...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].transform(\n",
    "                lambda x: x.interpolate(method='linear', limit_direction='both')\n",
    "            )\n",
    "    \n",
    "    # Method 4: Fill remaining with median (by district)\n",
    "    print(\"Step 4: Filling remaining with district median...\")\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df.groupby('district')[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "    \n",
    "    # Method 5: Fill any still-remaining with overall median (edge cases)\n",
    "    for col in impute_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    print(f\"\\n-> Missing values handled!\")\n",
    "    print(f\"   Before: {missing_before}\")\n",
    "    print(f\"   After: {missing_after}\")\n",
    "    print(f\"   Imputed: {missing_before - missing_after}\")\n",
    "else:\n",
    "    print(\"-> No missing values to handle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea56c0df-ab48-4260-a510-7a60fbf79294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: PREPARING FOR FEATURE ENGINEERING\n",
      "============================================================\n",
      "-> Data sorted by district and date\n",
      "\n",
      "Missing values before engineering: 63889\n",
      "   After: 0\n",
      "\n",
      "Data ready for feature engineering!\n",
      "  Shape: (112497, 13)\n",
      "  Date range: 2021-01-01 00:00:00 to 2024-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Prepare for Feature Engineering (Sort by District and Date)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: PREPARING FOR FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by district and date for proper time series handling\n",
    "df_reduced = df_reduced.sort_values(['district', 'date']).reset_index(drop=True)\n",
    "print(\"-> Data sorted by district and date\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_before = df_reduced.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nMissing values before engineering: {missing_before}\")\n",
    "print(f\"   After: {missing_after}\")\n",
    "\n",
    "print(f\"\\nData ready for feature engineering!\")\n",
    "print(f\"  Shape: {df_reduced.shape}\")\n",
    "print(f\"  Date range: {df_reduced['date'].min()} to {df_reduced['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf5857a-7196-4a2c-a8a2-7cd61ae72098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING LAGGED FEATURES\n",
      "============================================================\n",
      "Creating TB case lags...\n",
      "Creating climate variable lags...\n",
      "Creating pollution variable lags...\n",
      "-> Lagged features created!\n",
      "New shape: (112497, 54)\n",
      "Total lagged features: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: CREATING TIME LAG FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define lag periods (extending to 90 days / ~3 months)\n",
    "lag_periods = [ 14, 30, 60, 90, 120]\n",
    "\n",
    "# Variables to create lags for\n",
    "lag_variables = [\n",
    "    'tb_case', 'avg_temp', 'humidity', 'precipitation', \n",
    "    'pm10', 'so2', 'no2', 'co', 'o3', 'solar_radiation'\n",
    "]\n",
    "\n",
    "print(f\"-> Creating lag features for {len(lag_variables)} variables\")\n",
    "print(f\"   Lag periods: {lag_periods} days\")\n",
    "print(f\"   Total lag features to create: {len(lag_variables) * len(lag_periods)}\")\n",
    "\n",
    "# Create lag features\n",
    "for var in lag_variables:\n",
    "    for lag in lag_periods:\n",
    "        col_name = f'{var}_lag_{lag}'\n",
    "        df_reduced[col_name] = df_reduced.groupby('district')[var].shift(lag)\n",
    "        \n",
    "print(f\"\\n✓ Created {len(lag_variables) * len(lag_periods)} lag features\")\n",
    "print(f\"   New shape: {df_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea67bac-7292-4691-b9b1-1ca1b5acd59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING ROLLING AVERAGES\n",
      "============================================================\n",
      "Creating 7-day rolling averages...\n",
      "Creating 14-day rolling averages...\n",
      "Creating 30-day rolling averages...\n",
      "Creating 7-day rolling std...\n",
      "-> Rolling features created!\n",
      "New shape: (112497, 77)\n",
      "Total rolling features: 23\n"
     ]
    }
   ],
   "source": [
    "# create rolling averages\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ROLLING AVERAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 7-day rolling average for key variables\n",
    "print(\"Creating 7-day rolling averages...\")\n",
    "rolling_vars = ['tb_case', 'avg_temp', 'humidity', 'pm25', 'pm10', \n",
    "                'precipitation', 'aqi', 'solar_radiation']\n",
    "\n",
    "for var in rolling_vars:\n",
    "    df[f'{var}_roll_7'] = df.groupby('district')[var].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# 14-day rolling average\n",
    "print(\"Creating 14-day rolling averages...\")\n",
    "for var in rolling_vars:\n",
    "    df[f'{var}_roll_14'] = df.groupby('district')[var].transform(\n",
    "        lambda x: x.rolling(window=14, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# 30-day rolling average\n",
    "print(\"Creating 30-day rolling averages...\")\n",
    "key_vars = ['tb_case', 'avg_temp', 'pm25', 'humidity']\n",
    "for var in key_vars:\n",
    "    df[f'{var}_roll_30'] = df.groupby('district')[var].transform(\n",
    "        lambda x: x.rolling(window=30, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# Rolling standard deviation (captures variability)\n",
    "print(\"Creating 7-day rolling std...\")\n",
    "for var in ['avg_temp', 'pm25', 'humidity']:\n",
    "    df[f'{var}_roll_std_7'] = df.groupby('district')[var].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).std()\n",
    "    )\n",
    "\n",
    "print(f\"-> Rolling features created!\")\n",
    "print(f\"New shape: {df.shape}\")\n",
    "\n",
    "# Count rolling features\n",
    "rolling_features = [col for col in df.columns if 'roll' in col]\n",
    "print(f\"Total rolling features: {len(rolling_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee266d0f-6fb6-4166-a29e-fef6e44d3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING INTERACTION FEATURES\n",
      "============================================================\n",
      "-> Interaction features created!\n",
      "Total: 7\n",
      "   - temp_humidity\n",
      "   - pm25_humidity\n",
      "   - temp_precipitation\n",
      "   - temp_range\n",
      "   - pollution_index\n",
      "   - temp_pm25\n",
      "   - wind_pm25\n",
      "\n",
      "New shape: (112497, 84)\n"
     ]
    }
   ],
   "source": [
    "# Create interaction features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING INTERACTION FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Temperature × Humidity (affects disease transmission)\n",
    "df['temp_humidity'] = df['avg_temp'] * df['humidity']\n",
    "\n",
    "# PM2.5 × Humidity (wet particles affect respiratory health differently)\n",
    "df['pm25_humidity'] = df['pm25'] * df['humidity']\n",
    "\n",
    "# Temperature × Precipitation\n",
    "df['temp_precipitation'] = df['avg_temp'] * df['precipitation']\n",
    "\n",
    "# Temperature range (daily variation)\n",
    "df['temp_range'] = df['temp_max'] - df['temp_min']\n",
    "\n",
    "# Pollution index (combined effect)\n",
    "df['pollution_index'] = df['pm25'] + df['pm10'] + df['no2'] + df['so2']\n",
    "\n",
    "# Temperature × PM2.5\n",
    "df['temp_pm25'] = df['avg_temp'] * df['pm25']\n",
    "\n",
    "# Wind Speed × PM2.5 (wind disperses pollution)\n",
    "df['wind_pm25'] = df['wind_speed'] * df['pm25']\n",
    "\n",
    "print(\"-> Interaction features created!\")\n",
    "interaction_features = ['temp_humidity', 'pm25_humidity', 'temp_precipitation',\n",
    "                        'temp_range', 'pollution_index', 'temp_pm25', 'wind_pm25']\n",
    "print(f\"Total: {len(interaction_features)}\")\n",
    "for feat in interaction_features:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(f\"\\nNew shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77443e90-8f3c-4faf-b0a7-b92fdfe13b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HANDLING OUTLIERS\n",
      "============================================================\n",
      "pm25: 9062 outliers found\n",
      "pm10: 8218 outliers found\n",
      "so2: 9052 outliers found\n",
      "no2: 8912 outliers found\n",
      "co: 8714 outliers found\n",
      "o3: 709 outliers found\n",
      "\n",
      "-> Outliers handled!\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HANDLING OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def cap_outliers_iqr(data, columns, factor=1.5):\n",
    "    \"\"\"Cap outliers using IQR method\"\"\"\n",
    "    df_capped = data.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        Q1 = df_capped[col].quantile(0.25)\n",
    "        Q3 = df_capped[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        \n",
    "        # Count outliers\n",
    "        outliers = ((df_capped[col] < lower_bound) | (df_capped[col] > upper_bound)).sum()\n",
    "        \n",
    "        if outliers > 0:\n",
    "            print(f\"{col}: {outliers} outliers found\")\n",
    "            # Cap instead of remove (better for time series)\n",
    "            df_capped[col] = df_capped[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return df_capped\n",
    "\n",
    "# Apply to pollution variables (they often have extreme spikes)\n",
    "outlier_cols = ['pm25', 'pm10', 'so2', 'no2', 'co', 'o3', 'aqi']\n",
    "df = cap_outliers_iqr(df, outlier_cols, factor=1.5)\n",
    "\n",
    "print(\"\\n-> Outliers handled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63608cf8-3bb9-4f97-b288-5149a27ae53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DROPPING ROWS WITH NaN\n",
      "============================================================\n",
      "Shape before: (112497, 84)\n",
      "Total NaN values: 33033\n",
      "\n",
      "Columns with NaN:\n",
      "tb_lag_60                 4620\n",
      "tb_lag_30                 2310\n",
      "tb_lag_14                 1078\n",
      "temp_max_lag_14           1078\n",
      "avg_temp_lag_14           1078\n",
      "so2_lag_14                1078\n",
      "co_lag_14                 1078\n",
      "humidity_lag_14           1078\n",
      "temp_min_lag_14           1078\n",
      "wind_speed_lag_14         1078\n",
      "solar_radiation_lag_14    1078\n",
      "air_pressure_lag_14       1078\n",
      "precipitation_lag_14      1078\n",
      "pm10_lag_14               1078\n",
      "no2_lag_14                1078\n",
      "aqi_lag_14                1078\n",
      "o3_lag_14                 1078\n",
      "pm25_lag_14               1078\n",
      "tb_lag_7                   539\n",
      "avg_temp_lag_7             539\n",
      "precipitation_lag_7        539\n",
      "pm25_lag_7                 539\n",
      "solar_radiation_lag_7      539\n",
      "air_pressure_lag_7         539\n",
      "wind_speed_lag_7           539\n",
      "temp_min_lag_7             539\n",
      "temp_max_lag_7             539\n",
      "humidity_lag_7             539\n",
      "so2_lag_7                  539\n",
      "co_lag_7                   539\n",
      "no2_lag_7                  539\n",
      "pm10_lag_7                 539\n",
      "o3_lag_7                   539\n",
      "aqi_lag_7                  539\n",
      "avg_temp_roll_std_7         77\n",
      "pm25_roll_std_7             77\n",
      "humidity_roll_std_7         77\n",
      "dtype: int64\n",
      "\n",
      "Shape after: (107877, 84)\n",
      "Rows dropped: 4620\n",
      "Remaining NaN: 0\n",
      "\n",
      "-> NaN rows dropped!\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN (created by lagging/rolling)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DROPPING ROWS WITH NaN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Shape before: {df.shape}\")\n",
    "print(f\"Total NaN values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Show which columns have NaN\n",
    "nan_cols = df.isnull().sum()\n",
    "if nan_cols.sum() > 0:\n",
    "    print(\"\\nColumns with NaN:\")\n",
    "    print(nan_cols[nan_cols > 0].sort_values(ascending=False))\n",
    "\n",
    "# Drop rows with any NaN\n",
    "df_final = df.dropna()\n",
    "\n",
    "print(f\"\\nShape after: {df_final.shape}\")\n",
    "print(f\"Rows dropped: {df.shape[0] - df_final.shape[0]}\")\n",
    "print(f\"Remaining NaN: {df_final.isnull().sum().sum()}\")\n",
    "\n",
    "# Update df\n",
    "df = df_final.copy()\n",
    "\n",
    "print(\"\\n-> NaN rows dropped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb73bc7e-2bc5-419d-bb6a-7ec3a33b03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE - FINAL SUMMARY\n",
      "======================================================================\n",
      "Final shape: (107877, 84)\n",
      "  Rows: 107,877\n",
      "  Columns: 84\n",
      "\n",
      "Date range: 2021-03-02 00:00:00 to 2024-12-31 00:00:00\n",
      "Total days: 1400\n",
      "Number of districts: 77\n",
      "\n",
      "Feature categories:\n",
      "  Original features: 20\n",
      "  Temporal features: 0\n",
      "  Lagged features: 34\n",
      "  Rolling features: 23\n",
      "  Interaction features: 7\n",
      "  TOTAL: 84\n",
      "\n",
      "Missing values: 0\n",
      "\n",
      "Column names:\n",
      "   1. district\n",
      "   2. date\n",
      "   3. aqi\n",
      "   4. co\n",
      "   5. humidity\n",
      "   6. nh3\n",
      "   7. no2\n",
      "   8. o3\n",
      "   9. pm10\n",
      "  10. pm25\n",
      "  11. precipitation\n",
      "  12. air_pressure\n",
      "  13. so2\n",
      "  14. solar_radiation\n",
      "  15. tb_case\n",
      "  16. avg_temp\n",
      "  17. temp_max\n",
      "  18. temp_min\n",
      "  19. wind_pressure\n",
      "  20. wind_speed\n",
      "  21. tb_lag_7\n",
      "  22. tb_lag_14\n",
      "  23. tb_lag_30\n",
      "  24. tb_lag_60\n",
      "  25. avg_temp_lag_7\n",
      "  26. avg_temp_lag_14\n",
      "  27. temp_max_lag_7\n",
      "  28. temp_max_lag_14\n",
      "  29. temp_min_lag_7\n",
      "  30. temp_min_lag_14\n",
      "  31. humidity_lag_7\n",
      "  32. humidity_lag_14\n",
      "  33. precipitation_lag_7\n",
      "  34. precipitation_lag_14\n",
      "  35. air_pressure_lag_7\n",
      "  36. air_pressure_lag_14\n",
      "  37. wind_speed_lag_7\n",
      "  38. wind_speed_lag_14\n",
      "  39. solar_radiation_lag_7\n",
      "  40. solar_radiation_lag_14\n",
      "  41. pm25_lag_7\n",
      "  42. pm25_lag_14\n",
      "  43. pm10_lag_7\n",
      "  44. pm10_lag_14\n",
      "  45. so2_lag_7\n",
      "  46. so2_lag_14\n",
      "  47. no2_lag_7\n",
      "  48. no2_lag_14\n",
      "  49. co_lag_7\n",
      "  50. co_lag_14\n",
      "  51. o3_lag_7\n",
      "  52. o3_lag_14\n",
      "  53. aqi_lag_7\n",
      "  54. aqi_lag_14\n",
      "  55. tb_case_roll_7\n",
      "  56. avg_temp_roll_7\n",
      "  57. humidity_roll_7\n",
      "  58. pm25_roll_7\n",
      "  59. pm10_roll_7\n",
      "  60. precipitation_roll_7\n",
      "  61. aqi_roll_7\n",
      "  62. solar_radiation_roll_7\n",
      "  63. tb_case_roll_14\n",
      "  64. avg_temp_roll_14\n",
      "  65. humidity_roll_14\n",
      "  66. pm25_roll_14\n",
      "  67. pm10_roll_14\n",
      "  68. precipitation_roll_14\n",
      "  69. aqi_roll_14\n",
      "  70. solar_radiation_roll_14\n",
      "  71. tb_case_roll_30\n",
      "  72. avg_temp_roll_30\n",
      "  73. pm25_roll_30\n",
      "  74. humidity_roll_30\n",
      "  75. avg_temp_roll_std_7\n",
      "  76. pm25_roll_std_7\n",
      "  77. humidity_roll_std_7\n",
      "  78. temp_humidity\n",
      "  79. pm25_humidity\n",
      "  80. temp_precipitation\n",
      "  81. temp_range\n",
      "  82. pollution_index\n",
      "  83. temp_pm25\n",
      "  84. wind_pm25\n",
      "\n",
      "Data types:\n",
      "float64           82\n",
      "object             1\n",
      "datetime64[ns]     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Memory usage:\n",
      "  74.96 MB\n"
     ]
    }
   ],
   "source": [
    "# Summary of processed data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"  Rows: {df.shape[0]:,}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Total days: {(df['date'].max() - df['date'].min()).days}\")\n",
    "print(f\"Number of districts: {df['district'].nunique()}\")\n",
    "\n",
    "# Define feature categories\n",
    "temporal_features = ['year', 'month', 'day', 'day_of_week', 'week_of_year', \n",
    "                    'quarter', 'season', 'day_of_year', 'month_sin', 'month_cos', \n",
    "                    'day_sin', 'day_cos']\n",
    "\n",
    "interaction_features = ['temp_humidity', 'pm25_humidity', 'temp_precipitation',\n",
    "                        'temp_range', 'pollution_index', 'temp_pm25', 'wind_pm25']\n",
    "\n",
    "# Count features\n",
    "lagged_features = [col for col in df.columns if 'lag' in col]\n",
    "rolling_features = [col for col in df.columns if 'roll' in col]\n",
    "temporal_in_df = [col for col in df.columns if col in temporal_features]\n",
    "interaction_in_df = [col for col in df.columns if col in interaction_features]\n",
    "\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"  Original features: 20\")\n",
    "print(f\"  Temporal features: {len(temporal_in_df)}\")\n",
    "print(f\"  Lagged features: {len(lagged_features)}\")\n",
    "print(f\"  Rolling features: {len(rolling_features)}\")\n",
    "print(f\"  Interaction features: {len(interaction_in_df)}\")\n",
    "print(f\"  TOTAL: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(f\"  {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10453c07-3a36-4bcc-b9fd-b64bb166b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed data saved to: data/processed/tb_data_processed.csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "output_path = 'data/processed/tb_data_processed.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Processed data saved to: {output_path}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
